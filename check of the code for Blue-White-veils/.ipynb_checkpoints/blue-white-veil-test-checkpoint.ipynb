{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04bf455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of Blue-White Veil to Lesion: no\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_blue_white_ratio(image_path, mask_path):\n",
    "   # Load the image and mask\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if images were loaded successfully\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return\n",
    "    if mask is None:\n",
    "        print(f\"Error loading mask: {mask_path}\")\n",
    "        return\n",
    "\n",
    "    # Resize the mask to match the dimensions of the image\n",
    "    if image.shape[:2] != mask.shape[:2]:\n",
    "        print(\"Image and mask dimensions do not match. Resizing mask...\")\n",
    "        mask = cv2.resize(mask, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Convert image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define lower and upper bounds for blue color in HSV\n",
    "    lower_blue = np.array([90, 50, 50])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "\n",
    "    # Create a mask for blue color\n",
    "    blue_mask = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "\n",
    "    # Combine the blue mask with the original mask\n",
    "    combined_mask = cv2.bitwise_and(mask, mask, mask=blue_mask)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate area of blue-white veil\n",
    "    blue_white_area = cv2.countNonZero(combined_mask)\n",
    "\n",
    "    # Calculate area of the lesion (non-zero pixels in the mask)\n",
    "    lesion_area = cv2.countNonZero(mask)\n",
    "\n",
    "    # Calculate the ratio of blue-white veil area to lesion area\n",
    "    ratio = blue_white_area / lesion_area\n",
    "\n",
    "    if ratio>0.1:\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "# File paths relative to the script location\n",
    "image_path = '12.png'\n",
    "mask_path = '12_mask.png'\n",
    "\n",
    "# Calculate blue-white veil area ratio\n",
    "blue_white_ratio = calculate_blue_white_ratio(image_path, mask_path)\n",
    "print(f\"Ratio of Blue-White Veil to Lesion: {blue_white_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e254f6",
   "metadata": {},
   "source": [
    "for ratio>0.1:  \n",
    "1-yes  \n",
    "2-no  \n",
    "3-no  \n",
    "4-yes  \n",
    "5-yes  \n",
    "6-no  \n",
    "7-no  \n",
    "8-yes  \n",
    "9-no  \n",
    "10-yes  \n",
    "11-yes  \n",
    "12-no  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e33f47df",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'divide' output from dtype('float32') to dtype('uint8') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m mask_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2_mask.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Calculate blue-white presence based on the conditions\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m blue_white_presence \u001b[38;5;241m=\u001b[39m calculate_blue_white_presence(image_path, mask_path)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlue-White Veil Presence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblue_white_presence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 40\u001b[0m, in \u001b[0;36mcalculate_blue_white_presence\u001b[1;34m(image_path, mask_path)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Normalize features\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Normalize features\u001b[39;00m\n\u001b[0;32m     39\u001b[0m denominator \u001b[38;5;241m=\u001b[39m F4\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m+\u001b[39m F5\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m+\u001b[39m F6\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 40\u001b[0m F7 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdivide(F4\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32), denominator, out\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(F4), where\u001b[38;5;241m=\u001b[39mdenominator\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     41\u001b[0m F8 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdivide(F5\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32), denominator, out\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(F5), where\u001b[38;5;241m=\u001b[39mdenominator\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     42\u001b[0m F9 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdivide(F6\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32), denominator, out\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(F6), where\u001b[38;5;241m=\u001b[39mdenominator\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'divide' output from dtype('float32') to dtype('uint8') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_blue_white_presence(image_path, mask_path):\n",
    "    # Load the image and mask\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if images were loaded successfully\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return\n",
    "    if mask is None:\n",
    "        print(f\"Error loading mask: {mask_path}\")\n",
    "        return\n",
    "\n",
    "    # Resize the mask to match the dimensions of the image\n",
    "    if image.shape[:2] != mask.shape[:2]:\n",
    "        print(\"Image and mask dimensions do not match. Resizing mask...\")\n",
    "        mask = cv2.resize(mask, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Convert image to LAB color space\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Extract color channels\n",
    "    L, a, b = cv2.split(lab_image)\n",
    "    R, G, B = cv2.split(image)  # Define R, G, B here\n",
    "\n",
    "    # Calculate features\n",
    "    F1 = R + L\n",
    "    F2 = G + L\n",
    "    F3 = B + L\n",
    "    F4 = R - L\n",
    "    F5 = G - L\n",
    "    F6 = B - L\n",
    "\n",
    "    # Normalize features\n",
    "    # Normalize features\n",
    "    denominator = F4.astype(np.float32) + F5.astype(np.float32) + F6.astype(np.float32)\n",
    "    F7 = np.divide(F4.astype(np.float32), denominator, out=np.zeros_like(F4), where=denominator!=0)\n",
    "    F8 = np.divide(F5.astype(np.float32), denominator, out=np.zeros_like(F5), where=denominator!=0)\n",
    "    F9 = np.divide(F6.astype(np.float32), denominator, out=np.zeros_like(F6), where=denominator!=0)\n",
    "    F10 = R - np.mean(R)\n",
    "    F11 = G - np.mean(G)\n",
    "    F12 = B - np.mean(B)\n",
    "    F13 = np.divide(F10, F10 + F11 + F12, out=np.zeros_like(F10), where=(F10 + F11 + F12)!=0)\n",
    "    F14 = np.divide(F11, F10 + F11 + F12, out=np.zeros_like(F11), where=(F10 + F11 + F12)!=0)\n",
    "    F15 = np.divide(F12, F10 + F11 + F12, out=np.zeros_like(F12), where=(F10 + F11 + F12)!=0)\n",
    "\n",
    "    # Calculate blue-white presence based on conditions\n",
    "    if np.mean(F3) <= 0.3:\n",
    "        return \"0\"\n",
    "    elif np.mean(F10) > -51:\n",
    "        return \"0\"\n",
    "    elif np.mean(F10) <= -194:\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return \"1\"\n",
    "\n",
    "# File paths relative to the script location\n",
    "image_path = '2.png'\n",
    "mask_path = '2_mask.png'\n",
    "\n",
    "# Calculate blue-white presence based on the conditions\n",
    "blue_white_presence = calculate_blue_white_presence(image_path, mask_path)\n",
    "print(f\"Blue-White Veil Presence: {blue_white_presence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c62467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
